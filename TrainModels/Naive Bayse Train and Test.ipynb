{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceb92cce-6a2e-47fd-8378-eea87b256d11",
   "metadata": {},
   "source": [
    "MULTINOMIAL NAIVE BAYES SETTING PACKAGE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4116eb9-ef32-4439-a52b-3f264d5ebfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/meka/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/meka/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/meka/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os, types\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, precision_score, recall_score, accuracy_score, balanced_accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from joblib import dump, load\n",
    "import datetime\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d215a6-ae0a-476a-8405-d5fd631dcadf",
   "metadata": {},
   "source": [
    "READ DATA FOR MODEL CREATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e758798-7ba3-47e5-8841-7d37d4e97940",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel(\"data/Formulaire de collecte de données plats Camerounais (réponses).xlsx\",sheet_name=1)\n",
    "data['Plat']=data['Plat'].apply(lambda x : x.lower())\n",
    "data['Description']=data['Description'].apply(lambda x:text_clean(x,'L',True,'french'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11a4d852-b0ad-4af0-a109-64d407d80cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Plat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dorée appetisant</td>\n",
       "      <td>brochettes de bœuf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>viande petits morceau embrochés cuit braise .</td>\n",
       "      <td>brochettes de bœuf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>viande bœuf découpé morceau</td>\n",
       "      <td>brochettes de bœuf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>texture définit goût irrésistibles</td>\n",
       "      <td>brochettes de bœuf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>viande cuite disposé plateau</td>\n",
       "      <td>brochettes de bœuf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>appétissantes huileuses</td>\n",
       "      <td>brochettes de bœuf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>morceau chocolat</td>\n",
       "      <td>brochettes de bœuf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>brochette viande</td>\n",
       "      <td>brochettes de bœuf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>voir viande boeuf fri planche cuisine deux cou...</td>\n",
       "      <td>brochettes de bœuf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>viandes découpées petits morceau dorées .</td>\n",
       "      <td>brochettes de bœuf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description                 Plat\n",
       "0                                   dorée appetisant  brochettes de bœuf \n",
       "1      viande petits morceau embrochés cuit braise .  brochettes de bœuf \n",
       "2                        viande bœuf découpé morceau  brochettes de bœuf \n",
       "3                 texture définit goût irrésistibles  brochettes de bœuf \n",
       "4                       viande cuite disposé plateau  brochettes de bœuf \n",
       "5                            appétissantes huileuses  brochettes de bœuf \n",
       "6                                   morceau chocolat  brochettes de bœuf \n",
       "7                                   brochette viande  brochettes de bœuf \n",
       "8  voir viande boeuf fri planche cuisine deux cou...  brochettes de bœuf \n",
       "9          viandes découpées petits morceau dorées .  brochettes de bœuf "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983bc9c5-31b0-4a1a-9572-6636d06e9f70",
   "metadata": {},
   "source": [
    "TEXT PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a9f9580-1f23-4442-b9f1-056c7f627977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean(text, method, rm_stop, language):\n",
    "    text = re.sub(r\"\\n\",\"\",text)   #remove line breaks\n",
    "    text = text.lower() #convert to lowercase\n",
    "    text = re.sub(r\"\\d+\",\"\",text)   #remove digits and currencies \n",
    "    text = re.sub(r'[\\$\\d+\\d+\\$]', \"\", text)\n",
    "    text = re.sub(r'\\d+[\\.\\/-]\\d+[\\.\\/-]\\d+', '', text)   #remove dates \n",
    "    text = re.sub(r'\\d+[\\.\\/-]\\d+[\\.\\/-]\\d+', '', text)\n",
    "    text = re.sub(r'\\d+[\\.\\/-]\\d+[\\.\\/-]\\d+', '', text)\n",
    "    #text = re.sub(r'[^\\x00-\\x7f]',r' ',text)   #remove non-ascii\n",
    "    #text = re.sub(r'[^\\w\\s]','',text)   #remove punctuation\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)   #remove hyperlinks\n",
    "\n",
    "    #remove stop words\n",
    "    if rm_stop == True:\n",
    "        filtered_tokens = [word for word in word_tokenize(text) if not word in set(stopwords.words(language))]\n",
    "        text = \" \".join(filtered_tokens)\n",
    "\n",
    "    #lemmatization: typically preferred over stemming\n",
    "    if method == 'L':\n",
    "        lemmer = WordNetLemmatizer()\n",
    "        lemm_tokens = [lemmer.lemmatize(word) for word in word_tokenize(text)]\n",
    "        return \" \".join(lemm_tokens)\n",
    "\n",
    "    #stemming\n",
    "    if method == 'S':\n",
    "        porter = PorterStemmer()\n",
    "        stem_tokens = [porter.stem(word) for word in word_tokenize(text)]\n",
    "        return \" \".join(stem_tokens)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edafa434-3940-4334-a603-a11b7b74d274",
   "metadata": {},
   "source": [
    "MODEL DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2b7d3d79-7a7e-4479-b91a-54df0c0bd25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_model_data_w_tfidf_vectorizer(preprocessed_text, Y_train,  X_test, Y_test, alpha):\n",
    "    #vectorize dataset\n",
    "    tfidf = TfidfVectorizer()\n",
    "    vectorized_data = tfidf.fit_transform(preprocessed_text)\n",
    "\n",
    "    #define model\n",
    "    model = MultinomialNB(alpha=alpha)\n",
    "    model.fit(vectorized_data, Y_train)\n",
    "\n",
    "    #evaluate model\n",
    "    predictions = model.predict(tfidf.transform(X_test))\n",
    "\n",
    "    accuracy = accuracy_score( Y_test, predictions)\n",
    "    balanced_accuracy = balanced_accuracy_score(Y_test, predictions)\n",
    "    precision = precision_score(Y_test, predictions,average=None)\n",
    "\n",
    "    print(\"Accuracy:\",round(100*accuracy,2),'%')\n",
    "    print(\"Balanced accuracy:\",round(100*balanced_accuracy,2),'%')\n",
    "    print(\"Precision:\\n\", np.round(100*precision,2))\n",
    "    if accuracy>=0.6:\n",
    "        dump(model,f\"models/multinomial_naive_bayes_{str(datetime.datetime.now())}.joblib\")\n",
    "        dump(tfidf,f\"models/tfidf_vectorizer_{str(datetime.datetime.now())}.joblib\")\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b66abb-8e60-4b75-b4f4-02d21305661e",
   "metadata": {},
   "source": [
    "SPLIT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8fd53b34-cc6b-4c2f-8782-2f57bc0d2c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(data['Description'],\n",
    "                                                    data['Plat'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c0b593-06b6-4f90-8eeb-fe7109b26fc8",
   "metadata": {},
   "source": [
    "TRAINING AND TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "72036447-22ad-4771-9a21-9f481bcad56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.48 %\n",
      "Balanced accuracy: 72.47 %\n",
      "Precision:\n",
      " [100.    66.67  33.33  50.    33.33  42.86 100.    60.    25.    57.14\n",
      " 100.   100.   100.   100.    60.    14.29  60.    50.   100.   100.\n",
      " 100.   100.   100.   100.   100.   100.    33.33  57.14  50.   100.\n",
      " 100.   100.  ]\n"
     ]
    }
   ],
   "source": [
    "predictions=transform_model_data_w_tfidf_vectorizer(X_train,Y_train,X_test,Y_test, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e1e39789-cd48-41f8-960e-0ac2d713f2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['eru', 'jarret de porc', 'couscous manioc sauce pistache', 'koko',\n",
       "        'pommes pilees', 'ndole', 'poissson braise', 'bongo', 'sanga',\n",
       "        'gésiers saute', 'koko', 'okok', 'corntchap',\n",
       "        'couscous sauce gombo', 'corntchap', 'ndole', 'riz sauce arachide',\n",
       "        'couscous manioc sauce pistache', 'bongo', 'okok',\n",
       "        'taro sauce jaune', 'eru', 'sanga', 'riz saute',\n",
       "        'taro sauce jaune', 'corntchap', 'sauce gombo', 'poulet dg',\n",
       "        'pistache', 'jarret de porc', 'jarret de porc', 'okok',\n",
       "        'épinards saute aux gésiers de poulet', 'bongo', 'gésiers saute',\n",
       "        'poisson braise', 'sanga', 'brochettes de bœuf ',\n",
       "        'met de pistache', 'legumes sautes',\n",
       "        'couscous manioc sauce pistache', 'corntchap', 'poissson braise',\n",
       "        'sanga', 'corntchap', 'banane malaxee',\n",
       "        'macabo rape sauce arachide', 'sauce gombo', 'okok',\n",
       "        'legumes sautes', 'eru', 'brochettes de bœuf ',\n",
       "        'couscous manioc sauce pistache', 'riz saute', 'gésiers saute',\n",
       "        'jarret de porc', 'couscous manioc sauce pistache', 'koki',\n",
       "        'brochettes de bœuf ', 'bouillon de boeuf', 'brochettes de bœuf ',\n",
       "        'met de pistache', 'riz sauce tomate', 'sauce gombo',\n",
       "        'met de pistache', 'spaghetti sautes', 'bouillon de boeuf', 'eru',\n",
       "        'jarret de porc', 'couscous manioc sauce pistache', 'koki',\n",
       "        'macabo rape sauce arachide', 'taro sauce jaune',\n",
       "        'met de pistache', 'ndole', 'gésiers saute', 'bouillon de boeuf',\n",
       "        'koko', 'macabo rape sauce arachide', 'gésiers saute',\n",
       "        'taro sauce jaune', 'riz sauce tomate', 'pili pili',\n",
       "        'banane malaxee', 'ndole', 'pommes sautees', 'sanga', 'pili pili',\n",
       "        'sauce gombo', 'taro sauce jaune', 'met de pistache',\n",
       "        'gésiers saute', 'gésiers saute', 'ndole', 'poulet dg', 'eru',\n",
       "        'ndole', 'taro sauce jaune', 'pommes pilees', 'ndole', 'okok',\n",
       "        'sanga', 'couscous manioc sauce pistache', 'corntchap', 'sanga',\n",
       "        'koki', 'poissson braise', 'koko', 'riz saute', 'gésiers saute',\n",
       "        'pommes sautees', 'jarret de porc', 'koki', 'jarret de porc',\n",
       "        'taro sauce jaune'], dtype='<U36'),\n",
       " TfidfVectorizer(),\n",
       " MultinomialNB(alpha=0.05))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "afa2d22e-2524-4797-b7e6-a735da1cb650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Accuracy: 47.83 %\n",
      "Balanced accuracy: 53.27 %\n",
      "Precision:\n",
      " [100.    50.     0.    50.    33.33 100.     0.    23.08  25.    80.\n",
      "  57.14   0.     0.   100.    50.    11.76  23.08 100.     0.     0.\n",
      " 100.   100.   100.   100.   100.   100.     0.    44.44  28.57 100.\n",
      "  77.78   0.  ]\n",
      "0.1\n",
      "Accuracy: 63.48 %\n",
      "Balanced accuracy: 72.47 %\n",
      "Precision:\n",
      " [100.    66.67  50.    50.    40.    42.86 100.    50.    33.33  57.14\n",
      "  80.   100.   100.   100.    60.    14.29  42.86 100.   100.   100.\n",
      " 100.   100.   100.   100.   100.   100.    33.33  57.14  40.   100.\n",
      " 100.   100.  ]\n",
      "0.01\n",
      "Accuracy: 59.13 %\n",
      "Balanced accuracy: 66.87 %\n",
      "Precision:\n",
      " [100.    66.67  33.33  33.33  40.    37.5  100.    60.    25.    44.44\n",
      "  80.   100.   100.   100.    50.    14.29  50.    33.33 100.   100.\n",
      " 100.   100.   100.   100.   100.   100.    33.33  57.14  33.33 100.\n",
      " 100.     0.  ]\n",
      "0.001\n",
      "Accuracy: 57.39 %\n",
      "Balanced accuracy: 65.2 %\n",
      "Precision:\n",
      " [100.    40.    33.33  33.33  40.    37.5  100.    60.    28.57  44.44\n",
      " 100.   100.   100.   100.    50.    14.29  50.    33.33 100.   100.\n",
      " 100.   100.   100.   100.   100.   100.    33.33  50.    33.33 100.\n",
      "  88.89   0.  ]\n",
      "0.0001\n",
      "Accuracy: 58.26 %\n",
      "Balanced accuracy: 65.83 %\n",
      "Precision:\n",
      " [100.    33.33  33.33  50.    40.    60.   100.    60.    33.33  44.44\n",
      " 100.   100.   100.   100.    50.    14.29  33.33  33.33 100.   100.\n",
      " 100.   100.   100.   100.   100.   100.    33.33  50.    33.33 100.\n",
      "  77.78   0.  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meka/Documents/TP Dr Jiomekong/Projet-INF331-UY1-DMC-Food-/user_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for i in range(np.random.randint(0,10)):\n",
    "    print(1/10**(i))\n",
    "    predictions=transform_model_data_w_tfidf_vectorizer(X_train,Y_train,X_test,Y_test, 1/10**(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1a6ff3c1-ad8e-4924-8a9c-18af783d0d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "444427ec-59d8-4490-814a-5d0b07777389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Couscous avec viande de boeuf, okok']\n"
     ]
    }
   ],
   "source": [
    "#n=np.random.randint(0,len(data[\"Description\"]))\n",
    "#texte=data[\"Description\"].loc[n]\n",
    "texte=\"Couscous avec viande de boeuf, okok\"\n",
    "x_new=[texte]\n",
    "print(x_new)\n",
    "x_new[0]=text_clean(x_new[0],'L',True,'french')\n",
    "vectorizer=load(\"models/tfidf_vectorizer_2024-01-01 17:38:24.544074.joblib\")\n",
    "model=load(\"models/multinomial_naive_bayes_2024-01-01 17:38:24.541295.joblib\")\n",
    "x_new_transformed = vectorizer.transform(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a87b03a6-7fb9-46e7-a209-46d374379596",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=model.predict(x_new_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "26f9a714-e37f-483d-9718-4637dc1af786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'couscous manioc sauce pistache'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Plat\"].iloc[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0633bf31-e705-4233-a458-0797800738f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eru'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b5e63d-23c7-439f-a82e-b4bae9e791a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
